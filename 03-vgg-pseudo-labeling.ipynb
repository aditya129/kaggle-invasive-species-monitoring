{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights = 'imagenet',include_top=False)\n",
    "x = vgg16.get_layer('block5_conv3').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model_final = Model(inputs=vgg16.input, outputs=x)\n",
    "model_final.compile(optimizer=SGD(lr=0.00001, momentum=0.9, nesterov=True),  loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.load_weights('./weights-iter-3-epoch-09.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model_final.layers:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Data Generators\n",
    "datagen = ImageDataGenerator( \n",
    "    featurewise_center            = True,\n",
    "    rescale                       = 1.,\n",
    "    rotation_range                = 10,\n",
    "    width_shift_range             = .1,\n",
    "    height_shift_range            = .1,\n",
    "    shear_range                   = 0.2,\n",
    "    zoom_range                    = 0.2,\n",
    "    horizontal_flip               = True,\n",
    "    vertical_flip                 = False,\n",
    "    fill_mode                     = \"reflect\")\n",
    "\n",
    "# normalization neccessary for correct image input to VGG16\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "# no data augmentation for validation and test set\n",
    "validgen = ImageDataGenerator(rescale=1., featurewise_center=True)\n",
    "validgen.mean=np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 568 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width  = 600\n",
    "img_height = 450\n",
    "\n",
    "train_data_dir      = \"data/train\"\n",
    "validation_data_dir = \"data/valid\"\n",
    "test_data_dir       = \"data/test\"\n",
    "\n",
    "batch_size_val   = 32\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        directory   = validation_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_val,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "\n",
    "validation_samples = len(val_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.081546935696729939, 0.98415492957746475]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1727 images belonging to 2 classes.\n",
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 6\n",
    "batch_size_test  = 3\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        directory   = train_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_train,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = True)\n",
    "\n",
    "\n",
    "\n",
    "test_gen = datagen.flow_from_directory(\n",
    "        directory   = test_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_test,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = True)\n",
    "\n",
    "train_samples      = len(train_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "batch: 1\n",
      "batch: 2\n",
      "batch: 3\n",
      "batch: 4\n",
      "batch: 5\n",
      "batch: 6\n",
      "batch: 7\n",
      "batch: 8\n",
      "batch: 9\n",
      "batch: 10\n",
      "batch: 11\n",
      "batch: 12\n",
      "batch: 13\n",
      "batch: 14\n",
      "batch: 15\n",
      "batch: 16\n",
      "batch: 17\n",
      "batch: 18\n",
      "batch: 19\n",
      "batch: 20\n",
      "batch: 21\n",
      "batch: 22\n",
      "batch: 23\n",
      "batch: 24\n",
      "batch: 25\n",
      "batch: 26\n",
      "batch: 27\n",
      "batch: 28\n",
      "batch: 29\n",
      "batch: 30\n",
      "batch: 31\n",
      "batch: 32\n",
      "batch: 33\n",
      "batch: 34\n",
      "batch: 35\n",
      "batch: 36\n",
      "batch: 37\n",
      "batch: 38\n",
      "batch: 39\n",
      "batch: 40\n",
      "batch: 41\n",
      "batch: 42\n",
      "batch: 43\n",
      "batch: 44\n",
      "batch: 45\n",
      "batch: 46\n",
      "batch: 47\n",
      "batch: 48\n",
      "batch: 49\n",
      "batch: 50\n",
      "batch: 51\n",
      "batch: 52\n",
      "batch: 53\n",
      "batch: 54\n",
      "batch: 55\n",
      "batch: 56\n",
      "batch: 57\n",
      "batch: 58\n",
      "batch: 59\n",
      "batch: 60\n",
      "batch: 61\n",
      "batch: 62\n",
      "batch: 63\n",
      "batch: 64\n",
      "batch: 65\n",
      "batch: 66\n",
      "batch: 67\n",
      "batch: 68\n",
      "batch: 69\n",
      "batch: 70\n",
      "batch: 71\n",
      "batch: 72\n",
      "batch: 73\n",
      "batch: 74\n",
      "batch: 75\n",
      "batch: 76\n",
      "batch: 77\n",
      "batch: 78\n",
      "batch: 79\n",
      "batch: 80\n",
      "batch: 81\n",
      "batch: 82\n",
      "batch: 83\n",
      "batch: 84\n",
      "batch: 85\n",
      "batch: 86\n",
      "batch: 87\n",
      "batch: 88\n",
      "batch: 89\n",
      "batch: 90\n",
      "batch: 91\n",
      "batch: 92\n",
      "batch: 93\n",
      "batch: 94\n",
      "batch: 95\n",
      "batch: 96\n",
      "batch: 97\n",
      "batch: 98\n",
      "batch: 99\n",
      "batch: 100\n",
      "batch: 101\n",
      "batch: 102\n",
      "batch: 103\n",
      "batch: 104\n",
      "batch: 105\n",
      "batch: 106\n",
      "batch: 107\n",
      "batch: 108\n",
      "batch: 109\n",
      "batch: 110\n",
      "batch: 111\n",
      "batch: 112\n",
      "batch: 113\n",
      "batch: 114\n",
      "batch: 115\n",
      "batch: 116\n",
      "batch: 117\n",
      "batch: 118\n",
      "batch: 119\n",
      "batch: 120\n",
      "batch: 121\n",
      "batch: 122\n",
      "batch: 123\n",
      "batch: 124\n",
      "batch: 125\n",
      "batch: 126\n",
      "batch: 127\n",
      "batch: 128\n",
      "batch: 129\n",
      "batch: 130\n",
      "batch: 131\n",
      "batch: 132\n",
      "batch: 133\n",
      "batch: 134\n",
      "batch: 135\n",
      "batch: 136\n",
      "batch: 137\n",
      "batch: 138\n",
      "batch: 139\n",
      "batch: 140\n",
      "batch: 141\n",
      "batch: 142\n",
      "batch: 143\n",
      "batch: 144\n",
      "batch: 145\n",
      "batch: 146\n",
      "batch: 147\n",
      "batch: 148\n",
      "batch: 149\n",
      "batch: 150\n",
      "batch: 151\n",
      "batch: 152\n",
      "batch: 153\n",
      "batch: 154\n",
      "batch: 155\n",
      "batch: 156\n",
      "batch: 157\n",
      "batch: 158\n",
      "batch: 159\n",
      "batch: 160\n",
      "batch: 161\n",
      "batch: 162\n",
      "batch: 163\n",
      "batch: 164\n",
      "batch: 165\n",
      "batch: 166\n",
      "batch: 167\n",
      "batch: 168\n",
      "batch: 169\n",
      "batch: 170\n",
      "batch: 171\n",
      "batch: 172\n",
      "batch: 173\n",
      "batch: 174\n",
      "batch: 175\n",
      "batch: 176\n",
      "batch: 177\n",
      "batch: 178\n",
      "batch: 179\n",
      "batch: 180\n",
      "batch: 181\n",
      "batch: 182\n",
      "batch: 183\n",
      "batch: 184\n",
      "batch: 185\n",
      "batch: 186\n",
      "batch: 187\n",
      "batch: 188\n",
      "batch: 189\n",
      "batch: 190\n",
      "batch: 191\n",
      "batch: 192\n",
      "batch: 193\n",
      "batch: 194\n",
      "batch: 195\n",
      "batch: 196\n",
      "batch: 197\n",
      "batch: 198\n",
      "batch: 199\n",
      "batch: 200\n",
      "batch: 201\n",
      "batch: 202\n",
      "batch: 203\n",
      "batch: 204\n",
      "batch: 205\n",
      "batch: 206\n",
      "batch: 207\n",
      "batch: 208\n",
      "batch: 209\n",
      "batch: 210\n",
      "batch: 211\n",
      "batch: 212\n",
      "batch: 213\n",
      "batch: 214\n",
      "batch: 215\n",
      "batch: 216\n",
      "batch: 217\n",
      "batch: 218\n",
      "batch: 219\n",
      "batch: 220\n",
      "batch: 221\n",
      "batch: 222\n",
      "batch: 223\n",
      "batch: 224\n",
      "batch: 225\n",
      "batch: 226\n",
      "batch: 227\n",
      "batch: 228\n",
      "batch: 229\n",
      "batch: 230\n",
      "batch: 231\n",
      "batch: 232\n",
      "batch: 233\n",
      "batch: 234\n",
      "batch: 235\n",
      "batch: 236\n",
      "batch: 237\n",
      "batch: 238\n",
      "batch: 239\n",
      "batch: 240\n",
      "batch: 241\n",
      "batch: 242\n",
      "batch: 243\n",
      "batch: 244\n",
      "batch: 245\n",
      "batch: 246\n",
      "batch: 247\n",
      "batch: 248\n",
      "batch: 249\n",
      "batch: 250\n",
      "batch: 251\n",
      "batch: 252\n",
      "batch: 253\n",
      "batch: 254\n",
      "batch: 255\n",
      "batch: 256\n",
      "batch: 257\n",
      "batch: 258\n",
      "batch: 259\n",
      "batch: 260\n",
      "batch: 261\n",
      "batch: 262\n",
      "batch: 263\n",
      "batch: 264\n",
      "batch: 265\n",
      "batch: 266\n",
      "batch: 267\n",
      "batch: 268\n",
      "batch: 269\n",
      "batch: 270\n",
      "batch: 271\n",
      "batch: 272\n",
      "batch: 273\n",
      "batch: 274\n",
      "batch: 275\n",
      "batch: 276\n",
      "batch: 277\n",
      "batch: 278\n",
      "batch: 279\n",
      "batch: 280\n",
      "batch: 281\n",
      "batch: 282\n",
      "batch: 283\n",
      "batch: 284\n",
      "batch: 285\n",
      "batch: 286\n",
      "batch: 287\n"
     ]
    }
   ],
   "source": [
    "for i in range(math.ceil(train_samples/batch_size_train)):\n",
    "    print('batch: ' + str(i))\n",
    "    test_imgs, test_labels = next(test_gen)\n",
    "    train_imgs, train_labels = next(train_gen)\n",
    "    test_labels = model_final.predict(test_imgs)\n",
    "    test_labels = np.array([1. if x>=0.5 else 0. for x in test_labels])\n",
    "    full_batch_imgs = np.concatenate((train_imgs, test_imgs))\n",
    "    full_batch_labels = np.concatenate((train_labels, test_labels))\n",
    "    model_final.train_on_batch(full_batch_imgs, full_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.091945192684114524, 0.9859154929577465]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "batch: 1\n",
      "batch: 2\n",
      "batch: 3\n",
      "batch: 4\n",
      "batch: 5\n",
      "batch: 6\n",
      "batch: 7\n",
      "batch: 8\n",
      "batch: 9\n",
      "batch: 10\n",
      "batch: 11\n",
      "batch: 12\n",
      "batch: 13\n",
      "batch: 14\n",
      "batch: 15\n",
      "batch: 16\n",
      "batch: 17\n",
      "batch: 18\n",
      "batch: 19\n",
      "batch: 20\n",
      "batch: 21\n",
      "batch: 22\n",
      "batch: 23\n",
      "batch: 24\n",
      "batch: 25\n",
      "batch: 26\n",
      "batch: 27\n",
      "batch: 28\n",
      "batch: 29\n",
      "batch: 30\n",
      "batch: 31\n",
      "batch: 32\n",
      "batch: 33\n",
      "batch: 34\n",
      "batch: 35\n",
      "batch: 36\n",
      "batch: 37\n",
      "batch: 38\n",
      "batch: 39\n",
      "batch: 40\n",
      "batch: 41\n",
      "batch: 42\n",
      "batch: 43\n",
      "batch: 44\n",
      "batch: 45\n",
      "batch: 46\n",
      "batch: 47\n",
      "batch: 48\n",
      "batch: 49\n",
      "batch: 50\n",
      "batch: 51\n",
      "batch: 52\n",
      "batch: 53\n",
      "batch: 54\n",
      "batch: 55\n",
      "batch: 56\n",
      "batch: 57\n",
      "batch: 58\n",
      "batch: 59\n",
      "batch: 60\n",
      "batch: 61\n",
      "batch: 62\n",
      "batch: 63\n",
      "batch: 64\n",
      "batch: 65\n",
      "batch: 66\n",
      "batch: 67\n",
      "batch: 68\n",
      "batch: 69\n",
      "batch: 70\n",
      "batch: 71\n",
      "batch: 72\n",
      "batch: 73\n",
      "batch: 74\n",
      "batch: 75\n",
      "batch: 76\n",
      "batch: 77\n",
      "batch: 78\n",
      "batch: 79\n",
      "batch: 80\n",
      "batch: 81\n",
      "batch: 82\n",
      "batch: 83\n",
      "batch: 84\n",
      "batch: 85\n",
      "batch: 86\n",
      "batch: 87\n",
      "batch: 88\n",
      "batch: 89\n",
      "batch: 90\n",
      "batch: 91\n",
      "batch: 92\n",
      "batch: 93\n",
      "batch: 94\n",
      "batch: 95\n",
      "batch: 96\n",
      "batch: 97\n",
      "batch: 98\n",
      "batch: 99\n",
      "batch: 100\n",
      "batch: 101\n",
      "batch: 102\n",
      "batch: 103\n",
      "batch: 104\n",
      "batch: 105\n",
      "batch: 106\n",
      "batch: 107\n",
      "batch: 108\n",
      "batch: 109\n",
      "batch: 110\n",
      "batch: 111\n",
      "batch: 112\n",
      "batch: 113\n",
      "batch: 114\n",
      "batch: 115\n",
      "batch: 116\n",
      "batch: 117\n",
      "batch: 118\n",
      "batch: 119\n",
      "batch: 120\n",
      "batch: 121\n",
      "batch: 122\n",
      "batch: 123\n",
      "batch: 124\n",
      "batch: 125\n",
      "batch: 126\n",
      "batch: 127\n",
      "batch: 128\n",
      "batch: 129\n",
      "batch: 130\n",
      "batch: 131\n",
      "batch: 132\n",
      "batch: 133\n",
      "batch: 134\n",
      "batch: 135\n",
      "batch: 136\n",
      "batch: 137\n",
      "batch: 138\n",
      "batch: 139\n",
      "batch: 140\n",
      "batch: 141\n",
      "batch: 142\n",
      "batch: 143\n",
      "batch: 144\n",
      "batch: 145\n",
      "batch: 146\n",
      "batch: 147\n",
      "batch: 148\n",
      "batch: 149\n",
      "batch: 150\n",
      "batch: 151\n",
      "batch: 152\n",
      "batch: 153\n",
      "batch: 154\n",
      "batch: 155\n",
      "batch: 156\n",
      "batch: 157\n",
      "batch: 158\n",
      "batch: 159\n",
      "batch: 160\n",
      "batch: 161\n",
      "batch: 162\n",
      "batch: 163\n",
      "batch: 164\n",
      "batch: 165\n",
      "batch: 166\n",
      "batch: 167\n",
      "batch: 168\n",
      "batch: 169\n",
      "batch: 170\n",
      "batch: 171\n",
      "batch: 172\n",
      "batch: 173\n",
      "batch: 174\n",
      "batch: 175\n",
      "batch: 176\n",
      "batch: 177\n",
      "batch: 178\n",
      "batch: 179\n",
      "batch: 180\n",
      "batch: 181\n",
      "batch: 182\n",
      "batch: 183\n",
      "batch: 184\n",
      "batch: 185\n",
      "batch: 186\n",
      "batch: 187\n",
      "batch: 188\n",
      "batch: 189\n",
      "batch: 190\n",
      "batch: 191\n",
      "batch: 192\n",
      "batch: 193\n",
      "batch: 194\n",
      "batch: 195\n",
      "batch: 196\n",
      "batch: 197\n",
      "batch: 198\n",
      "batch: 199\n",
      "batch: 200\n",
      "batch: 201\n",
      "batch: 202\n",
      "batch: 203\n",
      "batch: 204\n",
      "batch: 205\n",
      "batch: 206\n",
      "batch: 207\n",
      "batch: 208\n",
      "batch: 209\n",
      "batch: 210\n",
      "batch: 211\n",
      "batch: 212\n",
      "batch: 213\n",
      "batch: 214\n",
      "batch: 215\n",
      "batch: 216\n",
      "batch: 217\n",
      "batch: 218\n",
      "batch: 219\n",
      "batch: 220\n",
      "batch: 221\n",
      "batch: 222\n",
      "batch: 223\n",
      "batch: 224\n",
      "batch: 225\n",
      "batch: 226\n",
      "batch: 227\n",
      "batch: 228\n",
      "batch: 229\n",
      "batch: 230\n",
      "batch: 231\n",
      "batch: 232\n",
      "batch: 233\n",
      "batch: 234\n",
      "batch: 235\n",
      "batch: 236\n",
      "batch: 237\n",
      "batch: 238\n",
      "batch: 239\n",
      "batch: 240\n",
      "batch: 241\n",
      "batch: 242\n",
      "batch: 243\n",
      "batch: 244\n",
      "batch: 245\n",
      "batch: 246\n",
      "batch: 247\n",
      "batch: 248\n",
      "batch: 249\n",
      "batch: 250\n",
      "batch: 251\n",
      "batch: 252\n",
      "batch: 253\n",
      "batch: 254\n",
      "batch: 255\n",
      "batch: 256\n",
      "batch: 257\n",
      "batch: 258\n",
      "batch: 259\n",
      "batch: 260\n",
      "batch: 261\n",
      "batch: 262\n",
      "batch: 263\n",
      "batch: 264\n",
      "batch: 265\n",
      "batch: 266\n",
      "batch: 267\n",
      "batch: 268\n",
      "batch: 269\n",
      "batch: 270\n",
      "batch: 271\n",
      "batch: 272\n",
      "batch: 273\n",
      "batch: 274\n",
      "batch: 275\n",
      "batch: 276\n",
      "batch: 277\n",
      "batch: 278\n",
      "batch: 279\n",
      "batch: 280\n",
      "batch: 281\n",
      "batch: 282\n",
      "batch: 283\n",
      "batch: 284\n",
      "batch: 285\n",
      "batch: 286\n",
      "batch: 287\n"
     ]
    }
   ],
   "source": [
    "for i in range(math.ceil(train_samples/batch_size_train)):\n",
    "    print('batch: ' + str(i))\n",
    "    test_imgs, test_labels = next(test_gen)\n",
    "    train_imgs, train_labels = next(train_gen)\n",
    "    test_labels = model_final.predict(test_imgs)\n",
    "    test_labels = np.array([1. if x>=0.5 else 0. for x in test_labels])\n",
    "    full_batch_imgs = np.concatenate((train_imgs, test_imgs))\n",
    "    full_batch_labels = np.concatenate((train_labels, test_labels))\n",
    "    model_final.train_on_batch(full_batch_imgs, full_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13198011181756697, 0.97359154929577463]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(math.ceil(train_samples/batch_size_train)):\n",
    "    test_imgs, test_labels = next(test_gen)\n",
    "    train_imgs, train_labels = next(train_gen)\n",
    "    test_labels = model_final.predict(test_imgs)\n",
    "    test_labels = np.array([1. if x>=0.5 else 0. for x in test_labels])\n",
    "    full_batch_imgs = np.concatenate((train_imgs, test_imgs))\n",
    "    full_batch_labels = np.concatenate((train_labels, test_labels))\n",
    "    model_final.train_on_batch(full_batch_imgs, full_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.091893477375519908, 0.98063380281690138]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(math.ceil(train_samples/batch_size_train)):\n",
    "    test_imgs, test_labels = next(test_gen)\n",
    "    train_imgs, train_labels = next(train_gen)\n",
    "    test_labels = model_final.predict(test_imgs)\n",
    "    test_labels = np.array([1. if x>=0.5 else 0. for x in test_labels])\n",
    "    full_batch_imgs = np.concatenate((train_imgs, test_imgs))\n",
    "    full_batch_labels = np.concatenate((train_labels, test_labels))\n",
    "    model_final.train_on_batch(full_batch_imgs, full_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.093184873635833915, 0.98239436619718312]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(math.ceil(train_samples/batch_size_train)):\n",
    "    test_imgs, test_labels = next(test_gen)\n",
    "    train_imgs, train_labels = next(train_gen)\n",
    "    test_labels = model_final.predict(test_imgs)\n",
    "    test_labels = np.array([1. if x>=0.5 else 0. for x in test_labels])\n",
    "    full_batch_imgs = np.concatenate((train_imgs, test_imgs))\n",
    "    full_batch_labels = np.concatenate((train_labels, test_labels))\n",
    "    model_final.train_on_batch(full_batch_imgs, full_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10197546908297464, 0.98415492957746475]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate_generator(val_gen, math.ceil(validation_samples/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
